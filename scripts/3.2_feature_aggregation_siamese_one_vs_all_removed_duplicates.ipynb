{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "import pdb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "    \n",
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 12, # 42, ~MAX 20 hours of training\n",
    "    \"train_batch_size\": 16,\n",
    "    \"valid_batch_size\": 64,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 5e-7,\n",
    "    \"T_max\": 12,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"fold\" : 0,\n",
    "    \"n_fold\": 5,\n",
    "    \"n_accumulate\": 1,\n",
    "    \"device\": get_available_device(),\n",
    "}\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(seed=CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the already preprocessed and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('../data/train_split_remove_duplicates_all_embeddings.pkl')\n",
    "valid_df = pd.read_pickle('../data/valid_split_remove_duplicates_all_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping in Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvedaDataset(Dataset):\n",
    "    def __init__(self, dataframe, labels = ['unable_to_assess', 'close_match', \n",
    "                                            'near_exact_match', 'exact_match']):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): A DataFrame containing 'ground_truth_embeddings', \n",
    "                                       'predicted_embeddings', and output columns.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "        # Convert embeddings to tensors\n",
    "        self.ground_truth_embeddings = torch.tensor(dataframe['ground_truth_embeddings'].tolist(), dtype=torch.float32)\n",
    "        self.predicted_embeddings = torch.tensor(dataframe['predicted_embeddings'].tolist(), dtype=torch.float32)\n",
    "        \n",
    "        # Get molecular smiles\n",
    "        self.ground_truth_smiles = dataframe['ground_truth_smiles'].to_list()\n",
    "        self.predicted_smiles = dataframe['predicted_smiles'].to_list()\n",
    "\n",
    "        # Convert labels to tensor\n",
    "        self.labels = torch.tensor(dataframe[labels].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples.\"\"\"\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Generates one sample of data.\"\"\"\n",
    "        return self.ground_truth_embeddings[idx].squeeze(0), self.predicted_embeddings[idx].squeeze(0), self.labels[idx]\n",
    "        # return self.ground_truth_smiles[idx], self.predicted_smiles[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5g/t9d5_kvd3kb4yljp4f0pvqqc0000gn/T/ipykernel_3618/3892128477.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)\n",
      "  self.ground_truth_embeddings = torch.tensor(dataframe['ground_truth_embeddings'].tolist(), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "#---\n",
    "trainset_unable = EnvedaDataset(dataframe=train_df, labels=['unable_to_assess'])\n",
    "validset_unable = EnvedaDataset(dataframe=valid_df, labels=['unable_to_assess'])\n",
    "\n",
    "#---\n",
    "trainset_not_close = EnvedaDataset(dataframe=train_df, labels=['not_close_match'])\n",
    "validset_not_close = EnvedaDataset(dataframe=valid_df, labels=['not_close_match'])\n",
    "\n",
    "#---\n",
    "trainset_close = EnvedaDataset(dataframe=train_df, labels=['close_match'])\n",
    "validset_close = EnvedaDataset(dataframe=valid_df, labels=['close_match'])\n",
    "\n",
    "#--\n",
    "trainset_near = EnvedaDataset(dataframe=train_df, labels=['near_exact_match'])\n",
    "validset_near = EnvedaDataset(dataframe=valid_df, labels=['near_exact_match'])\n",
    "\n",
    "#--\n",
    "trainset_exact = EnvedaDataset(dataframe=train_df, labels=['exact_match'])\n",
    "validset_exact = EnvedaDataset(dataframe=valid_df, labels=['exact_match'])\n",
    "\n",
    "#--\n",
    "trainset_prioritization = EnvedaDataset(dataframe=train_df, labels=['good_enough_for_prioritization'])\n",
    "validset_prioritization = EnvedaDataset(dataframe=valid_df, labels=['good_enough_for_prioritization'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping in Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader_unable = DataLoader(trainset_unable, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "validloader_unable = DataLoader(validset_unable, batch_size=CONFIG['valid_batch_size'], shuffle=False)\n",
    "\n",
    "trainloader_not_close = DataLoader(trainset_not_close, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "validloader_not_close = DataLoader(validset_not_close, batch_size=CONFIG['valid_batch_size'], shuffle=False)\n",
    "\n",
    "trainloader_close = DataLoader(trainset_close, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "validloader_close = DataLoader(validset_close, batch_size=CONFIG['valid_batch_size'], shuffle=False)\n",
    "\n",
    "trainloader_near = DataLoader(trainset_near, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "validloader_near = DataLoader(validset_near, batch_size=CONFIG['valid_batch_size'], shuffle=False)\n",
    "\n",
    "trainloader_exact = DataLoader(trainset_exact, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "validloader_exact = DataLoader(validset_exact, batch_size=CONFIG['valid_batch_size'], shuffle=False)\n",
    "\n",
    "trainloader_prioritization = DataLoader(trainset_prioritization, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "validloader_prioritization = DataLoader(validset_prioritization, batch_size=CONFIG['valid_batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 768]) torch.Size([16, 768]) torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "gt, pred, labels = next(iter(trainloader_unable))\n",
    "print(gt.shape, pred.shape, labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use larger Siamese network as in notebook 2.2_feature_aggregation_siamese_multiclass_FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Siamese Network\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_dim=768, output_dim=4):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "        nn.Linear(input_dim, 1024),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.2))\n",
    "\n",
    "        self.fc5 = nn.Linear(128, output_dim)\n",
    "\n",
    "        \n",
    "    def forward_one(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # pdb.set_trace()\n",
    "        # input1, input2 = self.smiler_embedder(**input1, output_hidden_states=True).pooler_output, \\\n",
    "        #                  self.smiler_embedder(**input2, output_hidden_states=True).pooler_output\n",
    "        \n",
    "        out1 = self.forward_one(input1)\n",
    "        out2 = self.forward_one(input2)\n",
    "        # pdb.set_trace()\n",
    "        # Combine both outputs by subtraction\n",
    "        combined = torch.sub(out1, out2)  # maybe torch.abs(out1 - out2)\n",
    "        output = self.fc5(combined)                  # Outputs raw logits\n",
    "        return output\n",
    "    \n",
    "    \n",
    "# model(gt, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseNetwork(output_dim=1)\n",
    "model.to(CONFIG['device'])\n",
    "model(gt.to(CONFIG['device']), pred.to(CONFIG['device']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validation regime\n",
    "\n",
    "## Training with mixed precision, gradient accumulation, learning with scheduler\n",
    "## Validation logging loss, AUROC, and F1 metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, criterion, scheduler, dataloader, epoch=CONFIG['epochs']):\n",
    "    model.train()\n",
    "    \n",
    "    scaler = GradScaler()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_auroc  = 0.0\n",
    "    running_f1 = 0.0\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        \n",
    "        gt, preds, targets = data\n",
    "        # gt, preds = tokenizer(gt, return_tensors='pt', padding=True, truncation=True)['input_ids'], \\\n",
    "        #             tokenizer(preds, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
    "        gt, preds, targets = gt.to(CONFIG['device']), preds.to(CONFIG['device']), targets.to(CONFIG['device'])\n",
    "        batch_size = targets.shape[0]\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(gt, preds)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss = loss / CONFIG['n_accumulate']\n",
    "            \n",
    "        # Backward pass with scaling\n",
    "        scaler.scale(loss).backward()\n",
    "    \n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            # Step the optimizer\n",
    "            scaler.step(optimizer)\n",
    "\n",
    "            # Update the scale for next iteration\n",
    "            scaler.update()\n",
    "            # optimizer.step()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "        \n",
    "        # pdb.set_trace()\n",
    "        probabilities = torch.softmax(outputs, dim=1).detach().cpu().numpy() if outputs.shape[1] > 1 else torch.sigmoid(outputs).detach().cpu().numpy()\n",
    "        preds = np.eye(outputs.shape[1])[np.argmax(probabilities, axis=1)] if outputs.shape[1] > 1 else (probabilities > 0.5).astype(float)\n",
    "        # pdb.set_trace()\n",
    "        auroc = average_precision_score(targets.cpu().numpy(), probabilities)\n",
    "        f1 = f1_score(targets.cpu().numpy(), preds, average='weighted')\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        running_auroc  += (auroc * batch_size)\n",
    "        running_f1 += (f1 * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        epoch_auroc = running_auroc / dataset_size\n",
    "        epoch_f1 = running_f1 / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, Train_Auroc=epoch_auroc, Train_F1=epoch_f1,\n",
    "                        LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, epoch_auroc, epoch_f1\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, criterion, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_auroc = 0.0\n",
    "    running_f1 = 0.0 \n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        \n",
    "        gt, preds, targets = data\n",
    "        # gt, preds = tokenizer(gt, return_tensors='pt', padding=True, truncation=True)['input_ids'], \\\n",
    "        #             tokenizer(preds, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
    "        gt, preds, targets = gt.to(CONFIG['device']), preds.to(CONFIG['device']), targets.to(CONFIG['device'])\n",
    "        batch_size = targets.shape[0]\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(gt, preds)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss = loss / CONFIG['n_accumulate']\n",
    "        \n",
    "        probabilities = torch.softmax(outputs, dim=1).detach().cpu().numpy() if outputs.shape[1] > 1 else torch.sigmoid(outputs).detach().cpu().numpy()\n",
    "        preds = np.eye(outputs.shape[1])[np.argmax(probabilities, axis=1)] if outputs.shape[1] > 1 else (probabilities > 0.5).astype(float)\n",
    "        \n",
    "        auroc = average_precision_score(targets.cpu().numpy(), probabilities)\n",
    "        f1 = f1_score(targets.cpu().numpy(), preds, average='weighted')\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        running_auroc  += (auroc * batch_size)\n",
    "        running_f1 += (f1 * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        epoch_auroc = running_auroc / dataset_size\n",
    "        epoch_f1 = running_f1 / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss, Valid_Auroc=epoch_auroc, \n",
    "                        Valid_F1=epoch_f1,\n",
    "                        )   \n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, epoch_auroc, epoch_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing components\n",
    "1. Model\n",
    "2. AdamW optimizer\n",
    "3. Cosine annealing scheduler\n",
    "4. Weighted cross entropy loss to handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models, optimizers, and schedulers for each dataset\n",
    "model_unable = SiameseNetwork(output_dim=1).to(CONFIG['device'])\n",
    "optimizer_unable = optim.AdamW(model_unable.parameters(), lr=CONFIG['learning_rate'], \n",
    "                               weight_decay=CONFIG['weight_decay'])\n",
    "scheduler_unable = lr_scheduler.CosineAnnealingLR(optimizer_unable, T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "\n",
    "model_close = SiameseNetwork(output_dim=1).to(CONFIG['device'])\n",
    "optimizer_close = optim.AdamW(model_close.parameters(), lr=CONFIG['learning_rate'], \n",
    "                               weight_decay=CONFIG['weight_decay'])\n",
    "scheduler_close = lr_scheduler.CosineAnnealingLR(optimizer_close, T_max=CONFIG['T_max'], \n",
    "                                                 eta_min=CONFIG['min_lr'])\n",
    "\n",
    "model_not_close = SiameseNetwork(output_dim=1).to(CONFIG['device'])\n",
    "optimizer_not_close = optim.AdamW(model_not_close.parameters(), lr=CONFIG['learning_rate'], \n",
    "                                   weight_decay=CONFIG['weight_decay'])\n",
    "scheduler_not_close = lr_scheduler.CosineAnnealingLR(optimizer_not_close, T_max=CONFIG['T_max'], \n",
    "                                                     eta_min=CONFIG['min_lr'])\n",
    "\n",
    "model_near = SiameseNetwork(output_dim=1).to(CONFIG['device'])\n",
    "optimizer_near = optim.AdamW(model_near.parameters(), lr=CONFIG['learning_rate'], \n",
    "                             weight_decay=CONFIG['weight_decay'])\n",
    "scheduler_near = lr_scheduler.CosineAnnealingLR(optimizer_near, T_max=CONFIG['T_max'], \n",
    "                                                eta_min=CONFIG['min_lr'])\n",
    "\n",
    "model_exact = SiameseNetwork(output_dim=1).to(CONFIG['device'])\n",
    "optimizer_exact = optim.AdamW(model_exact.parameters(), lr=CONFIG['learning_rate'], \n",
    "                               weight_decay=CONFIG['weight_decay'])\n",
    "scheduler_exact = lr_scheduler.CosineAnnealingLR(optimizer_exact, T_max=CONFIG['T_max'], \n",
    "                                                 eta_min=CONFIG['min_lr'])\n",
    "\n",
    "model_prioritization = SiameseNetwork(output_dim=1).to(CONFIG['device'])\n",
    "optimizer_prioritization = optim.AdamW(model_prioritization.parameters(), lr=CONFIG['learning_rate'], \n",
    "                                       weight_decay=CONFIG['weight_decay'])\n",
    "scheduler_prioritization = lr_scheduler.CosineAnnealingLR(optimizer_prioritization, T_max=CONFIG['T_max'],\n",
    "                                                          eta_min=CONFIG['min_lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable_to_assess                    7\n",
      "not_close_match                    87\n",
      "close_match                        99\n",
      "near_exact_match                   48\n",
      "exact_match                        11\n",
      "good_enough_for_prioritization    176\n",
      "dtype: int64\n",
      "{'unable_to_assess': 9.1, 'not_close_match': 0.8348623853211009, 'close_match': 0.728, 'near_exact_match': 1.378787878787879, 'exact_match': 7.583333333333333, 'good_enough_for_prioritization': 0.40625}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_df[['unable_to_assess','not_close_match','close_match', 'near_exact_match','exact_match', 'good_enough_for_prioritization']].sum())\n",
    "class_distribution = {'unable_to_assess': 10,\n",
    "                      'not_close_match': 109, \n",
    "                      'close_match': 125, \n",
    "                      'near_exact_match': 66, \n",
    "                      'exact_match': 12,\n",
    "                      'good_enough_for_prioritization': 224}\n",
    "\n",
    "# Calculate class weights\n",
    "total_samples = sum(class_distribution.values())\n",
    "class_weights = {label: total_samples / (len(class_distribution) * count) for label, count in class_distribution.items()}\n",
    "print(class_weights)\n",
    "\n",
    "# Convert class weights to tensors for each dataset\n",
    "pos_weights_unable = torch.tensor([class_weights['unable_to_assess']]).to(CONFIG['device'])\n",
    "pos_weights_not_close = torch.tensor([class_weights['not_close_match']]).to(CONFIG['device'])\n",
    "pos_weights_close = torch.tensor([class_weights['close_match']]).to(CONFIG['device'])\n",
    "pos_weights_near = torch.tensor([class_weights['near_exact_match']]).to(CONFIG['device'])\n",
    "pos_weights_exact = torch.tensor([class_weights['exact_match']]).to(CONFIG['device'])\n",
    "pos_weights_prioritization = torch.tensor([class_weights['good_enough_for_prioritization']]).to(CONFIG['device'])\n",
    "\n",
    "# Define the BCEWithLogitsLoss for each dataset\n",
    "criterion_unable = nn.BCEWithLogitsLoss(pos_weight=pos_weights_unable)\n",
    "criterion_not_close = nn.BCEWithLogitsLoss(pos_weight=pos_weights_not_close)\n",
    "criterion_close = nn.BCEWithLogitsLoss(pos_weight=pos_weights_close)\n",
    "criterion_near = nn.BCEWithLogitsLoss(pos_weight=pos_weights_near)\n",
    "criterion_exact = nn.BCEWithLogitsLoss(pos_weight=pos_weights_exact)\n",
    "criterion_prioritization = nn.BCEWithLogitsLoss(pos_weight=pos_weights_prioritization)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_one_epoch(model=model_exact, optimizer=optimizer_exact, criterion=criterion_exact, scheduler=scheduler_exact, dataloader=trainloader_exact)\n",
    "# valid_one_epoch(model=model_prioritization, dataloader=trainloader_prioritization, criterion=criterion_prioritization, epoch=CONFIG['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all together into training code\n",
    "Training code includes:\n",
    "1. Early stopping\n",
    "2. Saving best model weights according to supplied name\n",
    "3. Original code adapted from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_training(model, optimizer, scheduler, criterion, num_epochs, train_loader, valid_loader, name):\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_f1 = -np.inf\n",
    "    best_valid_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss, train_epoch_auroc, train_epoch_f1 = train_one_epoch(model=model, optimizer=optimizer, scheduler=scheduler, \n",
    "                                           criterion=criterion, dataloader=train_loader, \n",
    "                                           epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss, val_epoch_auroc, val_epoch_f1 = valid_one_epoch(model=model, dataloader=valid_loader, criterion=criterion, \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        history['Train AUROC'].append(train_epoch_auroc)\n",
    "        history['Valid AUROC'].append(val_epoch_auroc)\n",
    "        history['Valid F1'].append(val_epoch_f1)\n",
    "        history['lr'].append( scheduler.get_lr()[0] )\n",
    "        if val_epoch_loss <= best_valid_loss:\n",
    "            print(f\"Validation Loss Improved ({best_valid_loss} ---> {val_epoch_loss})\")\n",
    "            best_valid_loss = val_epoch_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"best_VAL_LOSS_model_{name}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved\")\n",
    "        \n",
    "        if best_epoch_f1 <= val_epoch_f1:\n",
    "            print(f\"Validation F1 Improved ({best_epoch_f1} ---> {val_epoch_f1})\")\n",
    "            best_epoch_f1 = val_epoch_f1\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"best_F1_model_{name}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best F1: {:.4f}\".format(best_epoch_f1))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_valid_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# Define a function to run the training for a single model\n",
    "def train_model(model, optimizer, scheduler, criterion, train_loader, valid_loader, name):\n",
    "    return run_training(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        criterion=criterion,\n",
    "        num_epochs=200,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=valid_loader,\n",
    "        name=name\n",
    "    )\n",
    "\n",
    "# Prepare model-specific parameters\n",
    "model_params = [\n",
    "    (model_unable, optimizer_unable, scheduler_unable, criterion_unable, trainloader_unable, validloader_unable, 'siamese_unable'),\n",
    "    (model_not_close, optimizer_not_close, scheduler_not_close, criterion_not_close, trainloader_not_close, validloader_not_close, 'siamese_not_close'),\n",
    "    (model_close, optimizer_close, scheduler_close, criterion_close, trainloader_close, validloader_close, 'siamese_close'),\n",
    "    (model_near, optimizer_near, scheduler_near, criterion_near, trainloader_near, validloader_near, 'siamese_near'),\n",
    "    (model_exact, optimizer_exact, scheduler_exact, criterion_exact, trainloader_exact, validloader_exact, 'siamese_exact'),\n",
    "    (model_prioritization, optimizer_prioritization, scheduler_prioritization, criterion_prioritization, trainloader_prioritization, validloader_prioritization, 'siamese_prioritization')\n",
    "]\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize the training\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(train_model, *params): name for params, name in zip(model_params, ['siamese_unable', 'siamese_close', 'siamese_near', 'siamese_exact', 'siamese_prioritization'])}\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        model_name = futures[future]\n",
    "        try:\n",
    "            trained_model, history = future.result()\n",
    "            print(f\"Training completed for model: {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model {model_name} generated an exception: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_unable.load_state_dict(torch.load('../results/one_vs_all/best_F1_model_siamese_unable.bin', map_location=torch.device(CONFIG['device'])))\n",
    "model_near.load_state_dict(torch.load('../results/one_vs_all/best_F1_model_siamese_near.bin', map_location=torch.device(CONFIG['device'])))\n",
    "model_not_close.load_state_dict(torch.load('../results/one_vs_all/best_F1_model_siamese_not_close.bin', map_location=torch.device(CONFIG['device'])))\n",
    "\n",
    "model_close.load_state_dict(torch.load('../results/one_vs_all/best_F1_model_siamese_close.bin', map_location=torch.device(CONFIG['device'])))\n",
    "model_exact.load_state_dict(torch.load('../results/one_vs_all/best_F1_model_siamese_exact.bin', map_location=torch.device(CONFIG['device'])))\n",
    "# model_prioritization.load_state_dict(torch.load('../results/best_F1_model_siamese_prioritization.bin', map_location=torch.device(CONFIG['device'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_unable.eval(), model_not_close.eval(), model_close.eval(), model_near.eval(), model_exact.eval()]\n",
    "# SAME ORDER OF PUTTING MODELS TOGETHER AS ORDER OF LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = EnvedaDataset(dataframe=train_df, labels=['unable_to_assess', 'not_close_match', 'close_match', \n",
    "                                                     'near_exact_match', 'exact_match'])\n",
    "validset = EnvedaDataset(dataframe=valid_df,  labels=['unable_to_assess', 'not_close_match', 'close_match', \n",
    "                                                     'near_exact_match', 'exact_match'])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "validloader = DataLoader(validset, batch_size=CONFIG['valid_batch_size'], shuffle=False)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Vs. All evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s, Epoch=1, Valid_Auroc=0.32, Valid_F1=0.232, Valid_Loss=0.768]/Users/awxlong/anaconda3/envs/ai/lib/python3.8/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Users/awxlong/anaconda3/envs/ai/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:980: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/awxlong/anaconda3/envs/ai/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "100%|██████████| 2/2 [00:00<00:00, 55.34it/s, Epoch=1, Valid_Auroc=0.308, Valid_F1=0.29, Valid_Loss=0.768]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "# Initialize metrics\n",
    "dataset_size = 0\n",
    "running_loss = 0.0\n",
    "running_auroc = 0.0\n",
    "running_f1 = 0.0 \n",
    "\n",
    "bar = tqdm(enumerate(validloader), total=len(validloader))\n",
    "for step, data in bar:\n",
    "    \n",
    "    gt, preds, targets = data\n",
    "    gt, preds, targets = gt.to(CONFIG['device']), preds.to(CONFIG['device']), targets.to(CONFIG['device'])\n",
    "    batch_size = gt.shape[0]\n",
    "    \n",
    "    # Initialize outputs for all models\n",
    "    all_outputs = []\n",
    "\n",
    "    with autocast():\n",
    "        for model in models:\n",
    "            outputs = model(gt, preds)  # Forward pass through each model\n",
    "            \n",
    "            # Store outputs for each model\n",
    "            all_outputs.append(outputs)\n",
    "\n",
    "        # Stack outputs from all models\n",
    "        combined_outputs = torch.cat(all_outputs, dim=1)  # Shape: (num_models, batch_size, num_classes)\n",
    "        # pdb.set_trace()\n",
    "        # Apply sigmoid or softmax based on the output shape\n",
    "        # if combined_outputs.shape[1] > 1:\n",
    "        #     probabilities = torch.softmax(combined_outputs, dim=1)  # Average over models\n",
    "        # else:\n",
    "        #     probabilities = torch.sigmoid(combined_outputs).mean(dim=0)  # Average over models\n",
    "        probabilities = torch.sigmoid(combined_outputs)/torch.sigmoid(combined_outputs).sum(dim=1, keepdim=True)\n",
    "        # Convert probabilities to predictions\n",
    "        preds = np.eye(probabilities.shape[1])[np.argmax(probabilities.detach().cpu().numpy(), axis=1)] if probabilities.shape[1] > 1 else (probabilities > 0.5).float()\n",
    "        # pdb.set_trace()\n",
    "        # Calculate loss (assuming you have a criterion defined)\n",
    "        loss = criterion(probabilities, targets)\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "    \n",
    "    # Compute metrics\n",
    "    auroc = average_precision_score(targets.cpu().numpy(), probabilities.detach().cpu().numpy(), average='macro')\n",
    "    f1 = f1_score(targets.cpu().numpy(), preds, average='weighted')\n",
    "    \n",
    "    # Update running totals\n",
    "    running_loss += (loss.item() * batch_size)\n",
    "    running_auroc += (auroc * batch_size)\n",
    "    running_f1 += (f1 * batch_size)\n",
    "    dataset_size += batch_size\n",
    "    \n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    epoch_auroc = running_auroc / dataset_size\n",
    "    epoch_f1 = running_f1 / dataset_size\n",
    "    \n",
    "    bar.set_postfix(Epoch=1, Valid_Loss=epoch_loss, Valid_Auroc=epoch_auroc, \n",
    "                    Valid_F1=epoch_f1,\n",
    "                    )   \n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_dict):\n",
    "    epochs = range(1, len(metrics_dict['Train Loss']) + 1)\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 15), sharex=True)\n",
    "\n",
    "    # Plot Train and Validation Loss\n",
    "    axs[0].plot(epochs, metrics_dict['Train Loss'], label='Train Loss', color='blue', marker='o')\n",
    "    axs[0].plot(epochs, metrics_dict['Valid Loss'], label='Valid Loss', color='orange', marker='o')\n",
    "    axs[0].set_title('Loss Over Epochs')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid()\n",
    "\n",
    "    # Plot Train and Validation AUROC\n",
    "    axs[1].plot(epochs, metrics_dict['Train AUROC'], label='Train AUROC', color='green', marker='o')\n",
    "    axs[1].plot(epochs, metrics_dict['Valid AUROC'], label='Valid AUROC', color='red', marker='o')\n",
    "    axs[1].set_title('AUROC Over Epochs')\n",
    "    axs[1].set_ylabel('AUROC Score')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid()\n",
    "\n",
    "    \n",
    "    # Plot Validation F1 Score\n",
    "    axs[2].plot(epochs, metrics_dict['Valid F1'], label='Valid F1 Score', color='purple', marker='o')\n",
    "    axs[2].set_title('Validation F1 Score Over Epochs')\n",
    "    axs[2].set_ylabel('F1 Score')\n",
    "    \n",
    "    \n",
    "    # Create a separate plot for Learning Rate\n",
    "    fig_lr, ax_lr = plt.subplots(figsize=(10, 5))\n",
    "    ax_lr.plot(epochs, metrics_dict['lr'], label='Learning Rate', color='cyan', linestyle='--', marker='o')\n",
    "    ax_lr.set_title('Learning Rate Over Epochs')\n",
    "    ax_lr.set_ylabel('Learning Rate')\n",
    "    ax_lr.grid()\n",
    "    fontsize = 12\n",
    "    # Label points for each plot\n",
    "    for i in range(0, len(metrics_dict['lr']), 10):\n",
    "        axs[0].text(epochs[i], metrics_dict['Train Loss'][i], f\"{metrics_dict['Train Loss'][i]:.2f}\", \n",
    "                    fontsize=fontsize, ha='right', color='k')\n",
    "        axs[0].text(epochs[i], metrics_dict['Valid Loss'][i], f\"{metrics_dict['Valid Loss'][i]:.2f}\", \n",
    "                    fontsize=fontsize, ha='right', color='k')\n",
    "        \n",
    "        axs[1].text(epochs[i], metrics_dict['Train AUROC'][i], f\"{metrics_dict['Train AUROC'][i]:.2f}\", \n",
    "                    fontsize=fontsize, ha='right', color='k')\n",
    "        axs[1].text(epochs[i], metrics_dict['Valid AUROC'][i], f\"{metrics_dict['Valid AUROC'][i]:.2f}\", \n",
    "                    fontsize=fontsize, ha='right', color='k')\n",
    "\n",
    "        axs[2].text(epochs[i], metrics_dict['Valid F1'][i], f\"{metrics_dict['Valid F1'][i]:.2f}\", \n",
    "                    fontsize=fontsize, ha='right', color='k')\n",
    "\n",
    "        ax_lr.text(epochs[i], metrics_dict['lr'][i], f\"{metrics_dict['lr'][i]:.4f}\", \n",
    "                   fontsize=fontsize, ha='right', color='k')\n",
    "\n",
    "    # Set common x-label\n",
    "    axs[-1].set_xlabel('Epochs')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show plots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
